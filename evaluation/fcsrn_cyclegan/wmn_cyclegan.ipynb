{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train wmn using additional generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add parent dir to syspath\n",
    "import os,sys,inspect\n",
    "current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "#root_dir = os.path.dirname(parent_dir)\n",
    "sys.path.insert(0, parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluationModels.scut_wmn.FCSRN import fcsrn\n",
    "from evaluationModels.scut_wmn import wmn_helpers\n",
    "from evaluationModels import evalFunctions\n",
    "\n",
    "from imageGenerators import load_digits, load_realdata\n",
    "from imageGenerators.imgGen_simple import synth_generator\n",
    "from models.cyclegan_modified.cyclegan import cyclegan\n",
    "\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import re\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert model is running on gpu\n",
    "from tensorflow.python.client import device_lib\n",
    "devlist = str(device_lib.list_local_devices())\n",
    "assert \"GPU:0\" in devlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to i2i-model to use for imagegeneration\n",
    "CHECKPOINTPATH = Path(\"D:/m2/savedmodels/checkpoints_cyclegan_modified_midstate\")\n",
    "EPOCH_OF_MODEL = 10\n",
    "\n",
    "generate_normalDigits = False\n",
    "generate_midstateDigits = False\n",
    "targetCount = None \n",
    "model_savepath = None\n",
    "\n",
    "\n",
    "model_savepath = Path(\"D:/m2/savedmodels/FCSRN_with_initializer\")\n",
    "targetCount = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate_normalDigits = True; generate_midstateDigits = False\n",
    "#model_savepath = Path(\"D:/m2/evaluations/fcsrn/add_normal\")\n",
    "#targetCount = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_normalDigits = False; generate_midstateDigits = True\n",
    "model_savepath = Path(\"D:/m2/evaluations/fcsrn/add_midstate2\")\n",
    "targetCount = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\m2\\evaluations\\fcsrn\\add_midstate2\n"
     ]
    }
   ],
   "source": [
    "assert model_savepath != None\n",
    "print(model_savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions of input to wmn-model\n",
    "HEIGHT = 48; WIDTH = 160; CHANNELS = 3\n",
    "IMAGE_SHAPE = (HEIGHT, WIDTH, CHANNELS)\n",
    "\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "N_DIGITS = 5   # digits per label\n",
    "N_CLASSES = 20 # there are 10 digits and 10 midstate-digits\n",
    "\n",
    "# get shape of inputs for i2i-model\n",
    "inputshapePath = CHECKPOINTPATH / \"inputshape\"\n",
    "cyclegan_inputShape = [int(s) for s in inputshapePath.read_text().split(\",\")]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load original data + labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\jupyter_ws\\evaluationModels\\scut_wmn\\wmn_helpers.py:52: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df_train = pd.read_csv(trainfile, sep=\"[ ,]\" ,header=None)\n",
      "C:\\Users\\andre\\jupyter_ws\\evaluationModels\\scut_wmn\\wmn_helpers.py:62: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df_test = pd.read_csv(testfile, sep=\"[ ,]\" ,header=None)\n",
      "C:\\Users\\andre\\jupyter_ws\\evaluationModels\\scut_wmn\\wmn_helpers.py:78: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv(file, sep=\"[ ,]\" ,header=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 48, 160, 3)\n",
      "(4000, 5)\n"
     ]
    }
   ],
   "source": [
    "images_train, labels_train, images_test, labels_test =  wmn_helpers.load_wmn_traindata(WIDTH, HEIGHT, keepRatio=True)\n",
    "images_easy, labels_easy = wmn_helpers.load_easySamples(WIDTH, HEIGHT, keepRatio=True)\n",
    "\n",
    "print(images_train.shape)\n",
    "print(labels_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "# find out how many of each digit to generate by counting each digit in trainingdata.\n",
    "# Returns: Map from digit to number to generate.\n",
    "####\n",
    "def countDigits(labels, targetDigitCount, useNormalDigits=True, useMidstateDigits=False, printResult=False):\n",
    "    print(\"counting digits\")\n",
    "    if not useNormalDigits and not useMidstateDigits:\n",
    "        return {}\n",
    "    firstDigit = 0 if useNormalDigits else 10\n",
    "    lastdigit = 20 if useMidstateDigits else 10\n",
    "    # count how often each digit occurs in traindata\n",
    "    digits, counts = np.unique(labels_train.flatten(), return_counts=True)\n",
    "    \n",
    "    # calculate how many of each digit to generate so that each occurs at least <targetDigitCount> times.\n",
    "    n_digitsToGenerate = {}\n",
    "    for digit in range(firstDigit, lastdigit):\n",
    "        n_digitsToGenerate[digit] = targetDigitCount - counts[digit] if counts[digit] < targetDigitCount else 0\n",
    "        \n",
    "    # the total number of generated digits must fit into labels of length <N_DIGITS>\n",
    "    sum_additionalDigits = sum(n_digitsToGenerate.values())\n",
    "    n_digitsToGenerate[np.random.randint(firstDigit, lastdigit)] += (N_DIGITS - sum_additionalDigits % N_DIGITS)\n",
    "    if printResult:\n",
    "        print(\"targetcount: %d\"%(targetDigitCount))\n",
    "        print(\"additional digits:\")\n",
    "        for key, value in sorted(n_digitsToGenerate.items(), key=lambda item: item[0]):\n",
    "            print(\"%d: %d\"%(key,value))\n",
    "        sum_additionalDigits = sum(n_digitsToGenerate.values())\n",
    "        print(\"total additional digits: %d\" % (sum_additionalDigits) )\n",
    "        print(\"total additional images: %f\"% (sum_additionalDigits/N_DIGITS) )\n",
    "    return n_digitsToGenerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "# generate synthetic images + labels from map n_toGenerate\n",
    "####\n",
    "def generate_synthetic(n_toGenerate):\n",
    "    print(\"generating synthetic images\")\n",
    "    # prepare labels\n",
    "    sum_additionalDigits = sum(n_toGenerate.values())\n",
    "    n_additionalImages = int(sum_additionalDigits / N_DIGITS)\n",
    "    labels_gen = np.concatenate([\n",
    "        np.full(shape=count, fill_value=digit) for digit, count in n_toGenerate.items()\n",
    "    ])\n",
    "    np.random.shuffle(labels_gen)\n",
    "    labels_gen = np.reshape(labels_gen, (n_additionalImages, N_DIGITS) )\n",
    "    \n",
    "    # generate images from labels\n",
    "    ####\n",
    "    # parameters for generator\n",
    "    ####\n",
    "    imageHeight = cyclegan_inputShape[0]\n",
    "    imageWidth = cyclegan_inputShape[1]\n",
    "    \n",
    "    # margins between digits, padding around resultimage \n",
    "    margins = [30 for _ in range(0, N_DIGITS - 1)]\n",
    "    padding = (0,0, 1,1) # top,bottom, left, right\n",
    "    # margin between digits in same column\n",
    "    vertical_margin = 20\n",
    "    ####\n",
    "    # ranges for how far digits can scroll up or down, 0 meaning no scrolling, 0.5 meaning halfway to next digit\n",
    "    range_normal=(-0.1,0.1)\n",
    "    range_midstate=(0.3,0.7)\n",
    "\n",
    "    ####\n",
    "    # whether to draw vertical seperator-lines between digits\n",
    "    draw_seperators = False\n",
    "\n",
    "    ####\n",
    "    # generate images\n",
    "    fontnumber = 29 # number of the font to use\n",
    "    dsPath = Path(\"C:/Users/andre/Desktop/m/datasets/Chars74K/English/Fnt\")\n",
    "    digitImages = load_digits.load_char74k(dsPath, fonts=[fontnumber - 1])  # index starts at zero, fontnumber at 1\n",
    "    synthGen = synth_generator(digitImages, vertical_margin)\n",
    "    images_synthetic = synthGen.generate_images(labels_gen, margins, padding, imageWidth, imageHeight, draw_vertical_seperators=draw_seperators, range_normal=range_normal,range_midstate=range_midstate)\n",
    "    \n",
    "    print(\"synthetic images:\")\n",
    "    for i in range(20):\n",
    "        image = images_synthetic[i]\n",
    "        plt.imshow(image, cmap=\"gray\")\n",
    "        plt.show()\n",
    "    \n",
    "    return (images_synthetic, labels_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translate synthetic images into realistic images using cyclegan\n",
    "def translate_images(synthImages, width=WIDTH, height=HEIGHT, keepRatio = True):\n",
    "    print(\"translating synthetic images to realistic images\")\n",
    "    ####\n",
    "    # load i2i model\n",
    "    cgModel = cyclegan(cyclegan_inputShape, checkpoint_path=CHECKPOINTPATH, load_checkpoint_after_epoch=EPOCH_OF_MODEL)\n",
    "    # prepare input for cgan\n",
    "    cgan_input = tf.data.Dataset.from_tensor_slices(synthImages)\\\n",
    "                .map(cgModel.preprocess_input, num_parallel_calls=AUTOTUNE)\\\n",
    "                .cache()\\\n",
    "                .batch(1)\n",
    "    ####\n",
    "    # predict realistic images\n",
    "    translated_images = cgModel.gen_AtoB.predict(cgan_input)\n",
    "    \n",
    "    # denormalize\n",
    "    translated_images = (translated_images + 1) * 127.5\n",
    "    \n",
    "    # resize to inputshape of wmn-model\n",
    "    if keepRatio:\n",
    "        translated_images = np.array([\n",
    "            wmn_helpers.resize_withPadding(image, width, height) for image in translated_images\n",
    "        ])\n",
    "    else:       \n",
    "        translated_images = np.array([\n",
    "            cv2.resize(image, (width, height)) for image in translated_images\n",
    "        ])\n",
    "        \n",
    "    print(\"translated images:\")\n",
    "    for i in range(20):\n",
    "        image = translated_images[i]\n",
    "        plt.imshow(image.astype(int), cmap=\"gray\")\n",
    "        plt.show()\n",
    "    \n",
    "    return translated_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def appendAndShuffle(imagesA, labelsA, imagesB, labelsB):\n",
    "    print(\"adding translated images to original traindata\")\n",
    "    # append\n",
    "    imagesA = np.append(imagesA, imagesB, axis=0)\n",
    "    labelsA = np.append(labelsA, labelsB, axis=0)\n",
    "    # zip and shuffle\n",
    "    trainset = list(zip(imagesA, labelsA))\n",
    "    random.shuffle(trainset)\n",
    "    # unzip\n",
    "    imagesA, labelsA = zip(*trainset)\n",
    "    return (np.array(imagesA), np.array(labelsA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_add_to_traindata(images_train=images_train, labels_train=labels_train, targetDigitCount=1000, useNormalDigits=False, useMidstateDigits=True):\n",
    "    # calc how many digits to generate\n",
    "    n_toGenerate = countDigits(labels_train, targetDigitCount, useNormalDigits=useNormalDigits, useMidstateDigits=useMidstateDigits, printResult=True)\n",
    "    # generate synthethic images\n",
    "    images_synthetic, labels_synthetic = generate_synthetic(n_toGenerate)\n",
    "    # translate synthethic images to realistic images\n",
    "    images_translated = translate_images(images_synthetic)\n",
    "    \n",
    "    # append translated dataset to original dataset, shuffle\n",
    "    images_train, labels_train = appendAndShuffle(images_train, labels_train, images_translated, labels_synthetic)   \n",
    "    \n",
    "    for i in range(30):\n",
    "        print(labels_synthetic[i])\n",
    "        plt.imshow(images_synthetic[i].astype(int), cmap=\"gray\")\n",
    "        plt.show()\n",
    "        plt.imshow(images_translated[i].astype(int), cmap=\"gray\")\n",
    "        plt.show()\n",
    "    \n",
    "    return images_train, labels_train, n_toGenerate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make tf-Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_datasets(images, labels):\n",
    "    X = tf.data.Dataset.from_tensor_slices(images)\\\n",
    "        .cache() \\\n",
    "        .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    y = tf.data.Dataset.from_tensor_slices(labels)\\\n",
    "        .cache() \\\n",
    "        .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    return (X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build/load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded checkpoint:  D:\\m2\\evaluations\\fcsrn\\add_midstate2\\epoch-100\n"
     ]
    }
   ],
   "source": [
    "modelExists = (model_savepath / \"checkpoint\").exists()\n",
    "model = fcsrn(IMAGE_SHAPE, checkpoint_path=model_savepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counting digits\n",
      "targetcount: 1000\n",
      "additional digits:\n",
      "10: 843\n",
      "11: 790\n",
      "12: 785\n",
      "13: 660\n",
      "14: 835\n",
      "15: 816\n",
      "16: 798\n",
      "17: 782\n",
      "18: 755\n",
      "19: 781\n",
      "total additional digits: 7845\n",
      "total additional images: 1569.000000\n",
      "not training because loaded trained model.\n"
     ]
    }
   ],
   "source": [
    "# avoid accidentally continuing training when loading trained model\n",
    "if not modelExists:    \n",
    "    images_train, labels_train, n_toGenerate = generate_and_add_to_traindata(targetDigitCount=targetCount, useNormalDigits=generate_normalDigits, useMidstateDigits=generate_midstateDigits)\n",
    "    train_X, train_y = make_datasets(images_train, labels_train)\n",
    "    \n",
    "    n_batches = len(images_train) / BATCH_SIZE\n",
    "    print(\"Training %d batches of size %d for %d epochs\" % (n_batches, BATCH_SIZE, EPOCHS) )\n",
    "    model.train(train_X, train_y, EPOCHS, BATCH_SIZE)\n",
    "else:\n",
    "    n_toGenerate = countDigits(labels_train, targetCount, useNormalDigits=generate_normalDigits, useMidstateDigits=generate_midstateDigits, printResult=True)\n",
    "    print(\"not training because loaded trained model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\andre\\Miniconda3\\envs\\keras_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py:5811: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "lcr: 0.787000\n",
      "ar: 0.954000\n"
     ]
    }
   ],
   "source": [
    "test_X, test_y = make_datasets(images_test, labels_test)\n",
    "N_TEST = len(images_test)\n",
    "total_characters = N_TEST * N_DIGITS\n",
    "lcr, ar, mismatches = model.accuracy(test_X, test_y, BATCH_SIZE, total_characters, N_TEST)\n",
    "print(\"lcr: %f\" % (lcr))\n",
    "print(\"ar: %f\" % (ar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder D:\\m2\\evaluations\\fcsrn\\add_midstate2\\errors already exists!\n",
      "folder D:\\m2\\evaluations\\fcsrn\\add_midstate2\\errors2 already exists!\n",
      "created dir: D:\\m2\\evaluations\\fcsrn\\add_midstate2\\errors3\n",
      "wrote evalfile to: D:\\m2\\evaluations\\fcsrn\\add_midstate2\\errors3\\errors.txt\n",
      "-------------------------------------\n",
      "Total Characters\n",
      "-------------------------------------\n",
      "digit\tcount(total=5000)\n",
      "0\t1651\n",
      "1\t828\n",
      "2\t314\n",
      "3\t300\n",
      "4\t118\n",
      "5\t230\n",
      "6\t201\n",
      "7\t294\n",
      "8\t360\n",
      "9\t209\n",
      "10\t37\n",
      "11\t37\n",
      "12\t58\n",
      "13\t81\n",
      "14\t54\n",
      "15\t36\n",
      "16\t40\n",
      "17\t36\n",
      "18\t68\n",
      "19\t48\n",
      "-------------------------------------\n",
      "Total Errors\n",
      "-------------------------------------\n",
      "digits missing:\t15\n",
      "digits extra:\t12\n",
      "digits replaced:\t209\n",
      "-------------------------------------\n",
      "Missing Digit Errors\n",
      "-------------------------------------\n",
      "\tDigits by #missed:\n",
      "digit\t#missing(total=15)\n",
      "0:\t2\n",
      "1:\t3\n",
      "3:\t1\n",
      "4:\t1\n",
      "5:\t1\n",
      "7:\t1\n",
      "8:\t1\n",
      "9:\t1\n",
      "10:\t1\n",
      "13:\t1\n",
      "14:\t1\n",
      "15:\t1\n",
      "\n",
      "\tList of every missing-error:\n",
      "missing\tpredicted\ttruth\n",
      "0\t[0 7 8 5] \t[0 0 7 8 5]\n",
      "0\t[0 7 8 5] \t[0 0 7 8 5]\n",
      "1\t[ 0  1  2 17] \t[0 1 2 1 1]\n",
      "1\t[ 0  1 13  6] \t[ 0  1 13  1  6]\n",
      "1\t[ 0  1  2 10] \t[ 0  1  2  1 10]\n",
      "3\t[0 1 0 9] \t[0 1 0 3 8]\n",
      "4\t[ 0  1  1 16] \t[0 1 1 4 9]\n",
      "5\t[0 1 0 0] \t[0 1 0 5 9]\n",
      "7\t[0 1 5 9] \t[0 1 5 7 9]\n",
      "8\t[0 1 0 5] \t[0 1 0 8 5]\n",
      "9\t[0 1 8 1] \t[0 1 8 9 1]\n",
      "10\t[ 0  0  8 19] \t[ 0  0  8 10 19]\n",
      "13\t[ 0  1  0 15] \t[ 0  1  0 13  2]\n",
      "14\t[ 0  1  2 19] \t[ 0  1  2 14 19]\n",
      "15\t[0 1 8 0] \t[ 0  1 15  0  0]\n",
      "-------------------------------------\n",
      "Extra Digit Errors\n",
      "-------------------------------------\n",
      "\tDigits by #extra:\n",
      "digit\t#extra(total=12)\n",
      "0:\t1\n",
      "1:\t1\n",
      "2:\t1\n",
      "8:\t1\n",
      "11:\t1\n",
      "12:\t1\n",
      "13:\t2\n",
      "14:\t1\n",
      "15:\t2\n",
      "18:\t1\n",
      "\n",
      "\tList of every extra-error:\n",
      "extra\tpredicted\ttruth\n",
      "0\t[0 0 0 8 9 9]   \t[0 0 8 9 9]\n",
      "1\t[0 1 1 9 3 7]   \t[0 1 9 3 1]\n",
      "2\t[ 0  1 13  2  0  0]   \t[ 0  1 13  0  0]\n",
      "8\t[0 1 0 5 8 8]   \t[0 1 0 5 0]\n",
      "11\t[ 0  0  0  3 11 11]   \t[ 0  0  0  3 11]\n",
      "12\t[ 0  1  0  2 12  5]   \t[0 1 0 2 5]\n",
      "13\t[ 0  0  7  4 13  4]   \t[0 0 7 4 4]\n",
      "13\t[ 0  1  5 13 13 19]   \t[ 0  1  5 13 19]\n",
      "14\t[ 0  0  7  0  5 14]   \t[0 0 7 0 5]\n",
      "15\t[ 0  0  0  2 15 15]   \t[ 0  0  0  2 18]\n",
      "15\t[ 0  0  7 15 15 19]   \t[ 0  0  7 15 19]\n",
      "18\t[ 0  1  0 15 19 18]   \t[ 0  1  0 15 19]\n",
      "-------------------------------------\n",
      "Replaced Digit Errors\n",
      "-------------------------------------\n",
      "\tTruthDigits by #mistaken\n",
      "truthdigit\t#mistaken(total=209)\n",
      "0:\t\t15\n",
      "1:\t\t6\n",
      "2:\t\t13\n",
      "3:\t\t9\n",
      "4:\t\t8\n",
      "5:\t\t8\n",
      "6:\t\t23\n",
      "7:\t\t10\n",
      "8:\t\t20\n",
      "9:\t\t12\n",
      "10:\t\t7\n",
      "11:\t\t3\n",
      "12:\t\t9\n",
      "13:\t\t20\n",
      "14:\t\t7\n",
      "15:\t\t4\n",
      "16:\t\t6\n",
      "17:\t\t9\n",
      "18:\t\t14\n",
      "19:\t\t6\n",
      "\tPredDigits by #mistake\n",
      "preddigit\t#misstake(total=209)\n",
      "0:\t\t10\n",
      "1:\t\t5\n",
      "2:\t\t2\n",
      "3:\t\t8\n",
      "4:\t\t21\n",
      "5:\t\t10\n",
      "6:\t\t14\n",
      "7:\t\t4\n",
      "8:\t\t14\n",
      "9:\t\t10\n",
      "10:\t\t9\n",
      "11:\t\t13\n",
      "12:\t\t12\n",
      "13:\t\t7\n",
      "14:\t\t10\n",
      "15:\t\t15\n",
      "16:\t\t9\n",
      "17:\t\t10\n",
      "18:\t\t11\n",
      "19:\t\t15\n",
      "\t replaced-pairs by #\n",
      "(pred,truth)\t#(total=209)\n",
      "(4, 13)  \t18\n",
      "(9, 8)  \t7\n",
      "(6, 8)  \t7\n",
      "(14, 4)  \t6\n",
      "(19, 18)  \t5\n",
      "(8, 6)  \t5\n",
      "(17, 7)  \t5\n",
      "(3, 12)  \t5\n",
      "(12, 2)  \t4\n",
      "(5, 6)  \t4\n",
      "(0, 9)  \t4\n",
      "(15, 6)  \t3\n",
      "(18, 6)  \t3\n",
      "(11, 2)  \t3\n",
      "(18, 8)  \t3\n",
      "(18, 16)  \t3\n",
      "(6, 0)  \t3\n",
      "(11, 17)  \t3\n",
      "(11, 12)  \t3\n",
      "(8, 17)  \t3\n",
      "(12, 3)  \t3\n",
      "(10, 0)  \t3\n",
      "(1, 10)  \t2\n",
      "(15, 2)  \t2\n",
      "(5, 0)  \t2\n",
      "(15, 5)  \t2\n",
      "(5, 14)  \t2\n",
      "(0, 5)  \t2\n",
      "(8, 9)  \t2\n",
      "(13, 2)  \t2\n",
      "(14, 19)  \t2\n",
      "(9, 6)  \t2\n",
      "(15, 18)  \t2\n",
      "(15, 17)  \t2\n",
      "(1, 0)  \t2\n",
      "(0, 6)  \t2\n",
      "(13, 3)  \t2\n",
      "(3, 5)  \t2\n",
      "(19, 15)  \t2\n",
      "(0, 19)  \t2\n",
      "(6, 9)  \t2\n",
      "(19, 9)  \t2\n",
      "(16, 7)  \t2\n",
      "(10, 1)  \t2\n",
      "(8, 0)  \t2\n",
      "(16, 10)  \t2\n",
      "(16, 18)  \t2\n",
      "(10, 6)  \t2\n",
      "(19, 14)  \t2\n",
      "(7, 3)  \t1\n",
      "(16, 9)  \t1\n",
      "(17, 1)  \t1\n",
      "(12, 19)  \t1\n",
      "(11, 7)  \t1\n",
      "(6, 5)  \t1\n",
      "(17, 18)  \t1\n",
      "(12, 13)  \t1\n",
      "(12, 5)  \t1\n",
      "(19, 16)  \t1\n",
      "(13, 10)  \t1\n",
      "(19, 10)  \t1\n",
      "(13, 16)  \t1\n",
      "(8, 18)  \t1\n",
      "(1, 7)  \t1\n",
      "(16, 15)  \t1\n",
      "(6, 17)  \t1\n",
      "(15, 0)  \t1\n",
      "(2, 11)  \t1\n",
      "(17, 8)  \t1\n",
      "(11, 1)  \t1\n",
      "(14, 0)  \t1\n",
      "(13, 4)  \t1\n",
      "(17, 11)  \t1\n",
      "(18, 9)  \t1\n",
      "(4, 7)  \t1\n",
      "(7, 2)  \t1\n",
      "(3, 6)  \t1\n",
      "(19, 2)  \t1\n",
      "(12, 18)  \t1\n",
      "(4, 14)  \t1\n",
      "(12, 11)  \t1\n",
      "(2, 4)  \t1\n",
      "(10, 3)  \t1\n",
      "(4, 1)  \t1\n",
      "(18, 10)  \t1\n",
      "(5, 3)  \t1\n",
      "(15, 19)  \t1\n",
      "(16, 6)  \t1\n",
      "(7, 1)  \t1\n",
      "(14, 15)  \t1\n",
      "(19, 0)  \t1\n",
      "(15, 12)  \t1\n",
      "(11, 18)  \t1\n",
      "(15, 14)  \t1\n",
      "(9, 18)  \t1\n",
      "(5, 8)  \t1\n",
      "(17, 3)  \t1\n",
      "(10, 13)  \t1\n",
      "(7, 8)  \t1\n",
      "(8, 16)  \t1\n",
      "(11, 14)  \t1\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logDir = model_savepath / \"errors\"\n",
    "# avoid accidentaly overwriting old logfiles\n",
    "counter = 1\n",
    "while logDir.exists():\n",
    "    print(\"folder %s already exists!\"%(logDir))\n",
    "    counter += 1\n",
    "    logDir = model_savepath / (\"errors%d\"%(counter))\n",
    "# save log\n",
    "evalFunctions.log_errors(mismatches, labels_test, savePath=logDir)\n",
    "# save accuracy\n",
    "accFile = logDir / \"accuracy.txt\"\n",
    "accFile.touch()\n",
    "accFile.write_text(\"lcr: %f\\nar: %f\"%(lcr,ar))\n",
    "# save what was generated\n",
    "summaryFile = logDir / \"about.txt\"\n",
    "summaryFile.touch()\n",
    "summary = \"\"\n",
    "summary += \"targetCount = %d\\n\"%(targetCount)\n",
    "summary += \"Generated Digits:\\n\"\n",
    "for digit, count in sorted(n_toGenerate.items()):\n",
    "    summary += \"%d:\\t%d\\n\"%(digit, count)\n",
    "summaryFile.write_text(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
