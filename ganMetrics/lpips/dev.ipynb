{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add parent dir to syspath\n",
    "import os,sys,inspect\n",
    "current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "root_dir = os.path.dirname(parent_dir)\n",
    "sys.path.insert(0, root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imageGenerators import load_realdata, distortions\n",
    "from imageGenerators.imgGen_simple import synth_generator\n",
    "from imageGenerators.imgGen_augmented import synth_generator as synth_generator_new\n",
    "\n",
    "from models.cyclegan_modified.cyclegan import cyclegan\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from time import time\n",
    "import re\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import lpips_interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showImage(image):\n",
    "    if len(image.shape) == 3 and image.shape[2] == 1:\n",
    "        image = image[:,:,0]\n",
    "    image = image.astype(int)\n",
    "    plt.imshow(image, cmap=\"gray\", vmin=0, vmax=255)\n",
    "    plt.show()\n",
    "def showImages(images, n, labels=None):\n",
    "    for i in range(min(n, len(images))):\n",
    "        if not labels is None:\n",
    "            print(labels[i])\n",
    "        image = images[i]\n",
    "        showImage(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcsrn_height = 48; fcsrn_width = 160; fcsrn_channels = 1\n",
    "fcsrn_shape = (fcsrn_height, fcsrn_width, fcsrn_channels)\n",
    "fcsrn_dims = (fcsrn_width, fcsrn_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep(image):\n",
    "    # norm to -1,1\n",
    "    image = image.astype(\"float32\")\n",
    "    image = (image / 127.5) - 1\n",
    "    # add channel-dims\n",
    "    shape = image.shape\n",
    "    shape = [d for d in shape]\n",
    "    shape.append(1)\n",
    "    if len(shape) == 3:\n",
    "        # add batch-dimensions if single image\n",
    "        shape.insert(0, 1)\n",
    "    image = np.reshape(image, shape)\n",
    "    # to 3-channel\n",
    "    image = tf.tile(image, [1, 1, 1, 3])\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pairs = 1900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diversitiy(images, n_pairs):\n",
    "    random_indices = np.random.randint(0,len(images), (2,n_pairs))\n",
    "    images_a = images[random_indices[0]]\n",
    "    images_b = images[random_indices[1]]\n",
    "    \n",
    "    images_a = prep(images_a)\n",
    "    images_b = prep(images_b)\n",
    "    \n",
    "    stime = time()\n",
    "    d = lpips_interface.distance(images_a,images_b)\n",
    "    print(\"%.2f seconds\" % (time() - stime) )\n",
    "    \n",
    "    mean = tf.math.reduce_mean(d)\n",
    "    maximum = tf.math.reduce_max(d)\n",
    "    minimum = tf.math.reduce_min(d)\n",
    "    \n",
    "    print(\"mean:\\t%f\" % (mean) )\n",
    "    print(\"maximum:\\t%f\" % (maximum) )\n",
    "    print(\"minimum:\\t%f\" % (minimum) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\jupyter_ws\\imageGenerators\\load_realdata.py:57: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv(txt_path, sep=seperators ,header=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.16 seconds\n",
      "mean:\t0.197358\n",
      "maximum:\t0.357190\n",
      "minimum:\t0.000000\n"
     ]
    }
   ],
   "source": [
    "# diversity real easy images with black padding\n",
    "images, _ = load_realdata.load_wmr_easy(n_toLoad = None, resizeTo=fcsrn_dims, keepRatio=True)\n",
    "diversitiy(images, n_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.53 seconds\n",
      "mean:\t0.188493\n",
      "maximum:\t0.323994\n",
      "minimum:\t0.000000\n"
     ]
    }
   ],
   "source": [
    "# diversity real easy images without padding\n",
    "images, _ = load_realdata.load_wmr_easy(n_toLoad = None, resizeTo=fcsrn_dims, keepRatio=False)\n",
    "diversitiy(images, n_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.55 seconds\n",
      "mean:\t0.295067\n",
      "maximum:\t0.565676\n",
      "minimum:\t0.060789\n"
     ]
    }
   ],
   "source": [
    "# diversity real diff images train with black padding\n",
    "images, _ = load_realdata.load_wmr_diff_train(n_toLoad = None, resizeTo=fcsrn_dims, keepRatio=True)\n",
    "diversitiy(images, n_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.53 seconds\n",
      "mean:\t0.282852\n",
      "maximum:\t0.522814\n",
      "minimum:\t0.046331\n"
     ]
    }
   ],
   "source": [
    "# diversity real diff images train without black padding\n",
    "images, _ = load_realdata.load_wmr_diff_train(n_toLoad = None, resizeTo=fcsrn_dims, keepRatio=False)\n",
    "diversitiy(images, n_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.53 seconds\n",
      "mean:\t0.289920\n",
      "maximum:\t0.558719\n",
      "minimum:\t0.000000\n"
     ]
    }
   ],
   "source": [
    "# diversity real diff images test with black padding\n",
    "images, _ = load_realdata.load_wmr_diff_test(n_toLoad = None, resizeTo=fcsrn_dims, keepRatio=True)\n",
    "diversitiy(images, n_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.53 seconds\n",
      "mean:\t0.283666\n",
      "maximum:\t0.491759\n",
      "minimum:\t0.000000\n"
     ]
    }
   ],
   "source": [
    "# diversity real diff images test without black padding\n",
    "images, _ = load_realdata.load_wmr_diff_test(n_toLoad = None, resizeTo=fcsrn_dims, keepRatio=False)\n",
    "diversitiy(images, n_pairs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
