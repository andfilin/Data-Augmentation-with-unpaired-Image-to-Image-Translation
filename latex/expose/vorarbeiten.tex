\chapter*{Vorarbeiten/Vorkenntnisse}
Eine Einführung in das Thema Machine Learning bietete die Vorlesung "`Vertiefung Datenbanksysteme"'
im zweiten Mastersemester.
Dort wurden Grundlegenede Begriffe und Verfahren behandelt, es wurden beispielsweise 
Algorithmen wie die Lineare Regresion, das 1-Regel-Verfahren und der Prism-Algorithmus
vorgestellt. Diese wurden im Praktikum mithilfe des Machine-Learning Tools WEKA\cite{weka} 
angewendet.

Als Einstieg in Neuronale Netze behandelte die Coursera-Spezialieserung "`Deep Learning"'\cite{coursera}, eine Menge von Onlinekursen welche mittels Videos
Wissen vermittelt, 
eine Vielfalt von Themen: Beispiele reichen von Aufbau, Funktionsweise und dahinterliegenden Algorithmen Neuronaler Netze,
über Optimierungen von Gradient Descent und
Strategien zum Aufbau eines Deep Learning Projekts 
(Aufteilung der Daten in Train/Dev/Test; Beschreibung veränderbarer Hyperparameter)
bis hin zu Convolutional Networks.
Auch wurden einige Beispiele Neuronaler Netzte vorgestellt, etwa ResNet oder Inception Network.

Einen Überblick über Generative Modelle bieteten je eine (auf Youtube verfügbare) Vorlesung zu diesem Thema vom MIT\cite{mit} und Stanford\cite{stan},
sowie zwei vom Erfinder von GANs gehaltene Präsentationen\cite{goodf1}\cite{goodf2} (ebenfalls auf Youtube verfügbar).

Zum Praktischen Einstieg erfolgte die Einarbeitung in das Machin-Learning Framework Keras\cite{Keras}.
Angefangen mit einer typischem "`Hello World"'-Anwendung, welche handgeschriebene Ziffern des MNIST-Datensatzes erkennt, 
wurde insbesondere ein Beispiel einer GAN-Anwendung\cite{ganex} implementiert, welche MNIST-Ziffern generiert.