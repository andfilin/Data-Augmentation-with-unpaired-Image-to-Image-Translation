{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add root dir to syspath\n",
    "import os,sys,inspect\n",
    "current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "root_dir = os.path.dirname(parent_dir)\n",
    "sys.path.insert(0, root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# own imports\n",
    "from models import image_preprocessing\n",
    "from imageGenerators import load_digits, load_realdata\n",
    "from imageGenerators.imgGen_simple import synth_generator\n",
    "from models.cyclegan_modified.cyclegan import cyclegan\n",
    "import models.common_functions \n",
    "# librarys\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "from os import listdir, mkdir\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert model is running on gpu\n",
    "from tensorflow.python.client import device_lib\n",
    "devlist = str(device_lib.list_local_devices())\n",
    "assert \"GPU:0\" in devlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_IMAGES = 5\n",
    "EPOCHS = 4\n",
    "N_TEST = 5\n",
    "N_DIGITS = 5\n",
    "BATCH_SIZE = 1\n",
    "BUFFER_SIZE = 1000\n",
    "\n",
    "# all images will be resized to these dimensions\n",
    "#                  width, height\n",
    "IMAGE_DIMENSIONS = (512, 128)\n",
    "#IMAGE_DIMENSIONS = (256, 256)\n",
    "GRAYSCALE = True\n",
    "N_CHANNELS = 1 if GRAYSCALE else 3\n",
    "#              height,              width,               channels\n",
    "IMAGE_SHAPE = (IMAGE_DIMENSIONS[1], IMAGE_DIMENSIONS[0], N_CHANNELS)\n",
    "\n",
    "#CHECKPOINTPATH = Path(\"D:/m2/savedmodels/test\")\n",
    "CHECKPOINTPATH = None # dont save model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate synthetic images (Domain A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the char74k datset\n",
    "datasetPath = Path(\"C:/Users/andre/Desktop/m/datasets/Chars74K/English/Fnt\")\n",
    "# make list mapping integers to list of images of that digit: \n",
    "digitImages = load_digits.load_char74k(datasetPath)\n",
    "# init imagegenerator\n",
    "synthGenerator = synth_generator(digitImages)\n",
    "# prepare inputdigits \n",
    "digitsTrain = np.random.randint(0,10,size=(N_IMAGES, N_DIGITS))\n",
    "digitsTest = np.random.randint(0,10,size=(N_TEST, N_DIGITS))\n",
    "# params to imagegenerator\n",
    "margins = [20 for _ in range(0, N_DIGITS - 1)] # distances between digits\n",
    "border = (2, 2, 2, 2) # padding of resultimage\n",
    "height = IMAGE_DIMENSIONS[1]; width= IMAGE_DIMENSIONS[0] # dimensions to resize result to\n",
    "# generate images\n",
    "synthTrain = synthGenerator.generate_images(digitsTrain, margins, border, width, height)\n",
    "synthTest = synthGenerator.generate_images(digitsTest, margins, border, width, height)\n",
    "\n",
    "plt.imshow(synthTrain[0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load real images (Domain B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmr_path = Path(\"C:/Users/andre/Desktop/m/datasets/SCUT-WMN DataSet/easy_samples\")\n",
    "real, paths_used = load_realdata.load_wmr(wmr_path, n_images=(N_IMAGES + N_TEST), resize_to=IMAGE_DIMENSIONS)\n",
    "realTrain = real[0:N_IMAGES]\n",
    "realTest = real[N_IMAGES:-1]\n",
    "\n",
    "plt.imshow(realTrain[0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make tf-Datasets\n",
    "train_A = tf.data.Dataset.from_tensor_slices(synthTrain)\n",
    "train_B = tf.data.Dataset.from_tensor_slices(realTrain)\n",
    "test_A = tf.data.Dataset.from_tensor_slices(synthTest)\n",
    "test_B = tf.data.Dataset.from_tensor_slices(realTest)\n",
    "# define preprocessing operations\n",
    "def preprocess(imageTensor):\n",
    "    # reshape (h,w) -> (h,w,1)\n",
    "    imageTensor = tf.reshape(imageTensor, (imageTensor.shape[0], imageTensor.shape[1], 1))\n",
    "    if(not GRAYSCALE):\n",
    "        # duplicate last dimension\n",
    "        imageTensor = tf.repeat(imageTensor, 3, axis=-1)\n",
    "    # to float\n",
    "    imageTensor = tf.cast(imageTensor, tf.float32)\n",
    "    # normalize\n",
    "    imageTensor = (imageTensor / 127.5) - 1\n",
    "    return imageTensor\n",
    "# apply preprocessing, cache and batch (data already shuffled)\n",
    "train_A = train_A \\\n",
    "        .map(preprocess, num_parallel_calls=AUTOTUNE) \\\n",
    "        .cache() \\\n",
    "        .batch(1)\n",
    "test_A = test_A \\\n",
    "        .map(preprocess, num_parallel_calls=AUTOTUNE) \\\n",
    "        .cache() \\\n",
    "        .batch(1)\n",
    "train_B = train_B \\\n",
    "        .map(preprocess, num_parallel_calls=AUTOTUNE) \\\n",
    "        .cache() \\\n",
    "        .batch(1)\n",
    "test_B = test_B \\\n",
    "        .map(preprocess, num_parallel_calls=AUTOTUNE) \\\n",
    "        .cache() \\\n",
    "        .batch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgModel = cyclegan(IMAGE_SHAPE, checkpoint_path=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgModel.gen_AtoB.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgModel.train(train_A, train_B, test_A, n_testimages=N_TEST, epochs=EPOCHS, epochs_before_save=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
