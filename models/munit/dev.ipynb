{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add root dir to syspath\n",
    "import os,sys,inspect\n",
    "current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "root_dir = os.path.dirname(parent_dir)\n",
    "sys.path.insert(0, root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import encoder\n",
    "import decoder\n",
    "import discriminator\n",
    "from imageGenerators import load_realdata\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = (512,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(image):\n",
    "    image = image.astype(\"float32\")\n",
    "    image = (image / 127.5) - 1\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\jupyter_ws\\imageGenerators\\load_realdata.py:62: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv(txt_path, sep=seperators ,header=None)\n"
     ]
    }
   ],
   "source": [
    "images_real, labels_real = load_realdata.load_wmr_easy(n_toLoad = 10, resizeTo=dims, keepRatio=True, processImage=None, channels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_real = np.array([\n",
    "    normalize_image(image) for image in images_real\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 128, 512, 1)\n"
     ]
    }
   ],
   "source": [
    "print(images_real.shape)\n",
    "image_shape = images_real.shape[1:None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 32, 128, 256)\n"
     ]
    }
   ],
   "source": [
    "encoder_content = encoder.content_model(image_shape)\n",
    "code_content = encoder_content.predict(images_real)\n",
    "print(code_content.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 8)\n"
     ]
    }
   ],
   "source": [
    "encoder_style = encoder.style_model(image_shape)\n",
    "code_style = encoder_style.predict(images_real)\n",
    "print(code_style.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adain_params = decoder.mlp(code_style.shape[1], 8)(code_style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'adain_params.shape\\n\\nadain_index=0\\n\\ngamma = adain_params[:, adain_index]\\nbeta = adain_params[:, adain_index+1]\\n\\n\\naxis = [1,2]\\nt = code_content\\nmean = tf.math.reduce_mean(t, axis=axis, keepdims=True)\\nstd = tf.math.reduce_std(t, axis=axis, keepdims=True)\\nresult = (t - mean) / std\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"adain_params.shape\n",
    "\n",
    "adain_index=0\n",
    "\n",
    "gamma = adain_params[:, adain_index]\n",
    "beta = adain_params[:, adain_index+1]\n",
    "\n",
    "\n",
    "axis = [1,2]\n",
    "t = code_content\n",
    "mean = tf.math.reduce_mean(t, axis=axis, keepdims=True)\n",
    "std = tf.math.reduce_std(t, axis=axis, keepdims=True)\n",
    "result = (t - mean) / std\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(result.shape)\n",
    "#g = tf.reshape(gamma, (-1, 1, 1, 256) )\n",
    "#print(gamma.shape)\n",
    "#x = gamma * result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!! ------------------------\n",
      "layer-normalization not implemented yet. for now, not using any normalization on upscaling layers. Implement later and compare results\n",
      "!!! ------------------------\n",
      "!!! ------------------------\n",
      "layer-normalization not implemented yet. for now, not using any normalization on upscaling layers. Implement later and compare results\n",
      "!!! ------------------------\n"
     ]
    }
   ],
   "source": [
    "dec = decoder.model(code_content.shape[1:None], code_style.shape[1:None], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = dec.predict([code_content, code_style])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 128, 512, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = discriminator.model(image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1)\n"
     ]
    }
   ],
   "source": [
    "prediction = disc.predict(result)\n",
    "print(prediction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 3)\n"
     ]
    }
   ],
   "source": [
    "disc_s = discriminator.multiscale_model(image_shape)\n",
    "prediction = disc_s.predict(result)\n",
    "print(prediction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.73011800e-06  7.54665962e-07 -3.01251112e-06]\n",
      " [ 1.54007721e-05  2.01672592e-05  5.76512684e-06]\n",
      " [ 6.64161053e-06  1.04686151e-05  2.11001716e-05]\n",
      " [-7.06275750e-06  1.02250369e-05  1.17849495e-05]\n",
      " [ 4.68221106e-06  1.50058167e-06  6.46831040e-06]\n",
      " [ 1.66401351e-05  1.41794953e-05  1.64186476e-05]\n",
      " [ 5.17356511e-06 -1.57510385e-06 -9.80326240e-06]\n",
      " [-1.91500985e-05 -3.07666232e-06 -2.35374555e-05]\n",
      " [-1.04278042e-05 -2.03329218e-05 -9.43543637e-06]\n",
      " [-6.24820041e-06 -1.03040611e-05 -1.63328878e-05]]\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-20-759c4c5efcf3>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-20-759c4c5efcf3>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    ----\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tf.constant([\n",
    "    [1,2,3],\n",
    "    [2,2,3],\n",
    "    [3,2,3],\n",
    "    [4,2,3],\n",
    "    [5,2,3],\n",
    "])\n",
    "\n",
    "print(t)\n",
    "\n",
    "x = tf.slice(\n",
    "    t, (0,1), (-1,1)\n",
    ")\n",
    "\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = tf.math.reduce_mean(t)\n",
    "print(m)\n",
    "\n",
    "y = tf.reshape(t, (None,1) )\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tf.range(0, 100, 1)\n",
    "t = tf.reshape(t, (10,2,5))\n",
    "u = tf.range(0, 50, 1)\n",
    "u = tf.reshape(u, (10,5))\n",
    "print(t)\n",
    "print(u)\n",
    "\n",
    "y = t-u\n",
    "print(y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
